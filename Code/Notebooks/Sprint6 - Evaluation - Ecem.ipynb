{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 21:54:05,243\tINFO util.py:159 -- Outdated packages:\n",
      "  ipywidgets==7.6.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-25 21:54:05,393\tINFO util.py:159 -- Outdated packages:\n",
      "  ipywidgets==7.6.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import tweetnlp\n",
    "import openai\n",
    "\n",
    "# Importing functions\n",
    "import sys\n",
    "sys.path.append('../Functions/')  # Adjust the relative path as needed\n",
    "\n",
    "from json_transform import get_all_keys, flatten_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Transform the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sample_tweets_complete - Erjon.csv file is used as input.\n",
    "This is done to compare the result with the survey.\n",
    "\n",
    "'''\n",
    "all_tweets = pd.read_csv(\"../../Data/Processed/Sprint4 - sample_tweets_complete - Erjon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 tweets in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Printing tweet length\n",
    "print(\"There are {} tweets in the dataset\".format(len(all_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93 tweets left after filtering out the rows that contain 'update' in the text column.\n"
     ]
    }
   ],
   "source": [
    "# Filtering out the rows that contain \"update\" in the text column\n",
    "\n",
    "all_tweets = all_tweets[~all_tweets['text'].str.contains(\"update\")]\n",
    "number_total_tweets = all_tweets.shape[0]\n",
    "\n",
    "# Printing tweet length after filtering out the rows that contain \"update\" in the text column\n",
    "\n",
    "print(\"There are \" + str(number_total_tweets) + \" tweets left after filtering out the rows that contain 'update' in the text column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 93\n",
      "Total number of tweets after dropping duplicates: 93\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will now drop the columns that we don't need and rename the columns that we will use.\n",
    "Then split the source_created_at column into date and time for easier analysis.\n",
    "Finally, we will drop the duplicated tweets.\n",
    "'''\n",
    "\n",
    "transformed_tweets = all_tweets[['text', 'author_id', 'source_created_at']].copy()\n",
    "print(f'Total number of tweets: {transformed_tweets.shape[0]}')\n",
    "\n",
    "transformed_tweets['date'] = transformed_tweets['source_created_at'].apply(lambda x: x.split(' ')[0])\n",
    "transformed_tweets['time'] = transformed_tweets['source_created_at'].apply(lambda x: x.split(' ')[1].split('.')[0])\n",
    "transformed_tweets.drop(['source_created_at'], axis=1, inplace=True)\n",
    "\n",
    "transformed_tweets = transformed_tweets.drop_duplicates(subset=['text'])\n",
    "\n",
    "print(f'Total number of tweets after dropping duplicates: {transformed_tweets.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filter the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54 tweets left after filtering out the rows that contain 'delay' in the text column.\n"
     ]
    }
   ],
   "source": [
    "# Checking transform_tweets dataframe and remove text that contains \"delay\" in the text column\n",
    "transformed_tweets = transformed_tweets[~transformed_tweets['text'].str.contains(\"delay\")]\n",
    "number_total_tweets = transformed_tweets.shape[0]\n",
    "\n",
    "# Printing tweet length after filtering out the rows that contain \"update\" in the text column\n",
    "print(\"There are \" + str(number_total_tweets) + \" tweets left after filtering out the rows that contain 'delay' in the text column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ironic tweets: 10\n"
     ]
    }
   ],
   "source": [
    "# Checking for irony in the tweets using the tweetnlp library and save the results in a new column called irony\n",
    "model_irony = tweetnlp.load_model('irony')\n",
    "transformed_tweets_irony = transformed_tweets.copy()\n",
    "transformed_tweets_irony['irony'] = transformed_tweets_irony['text'].apply(lambda x: model_irony.predict(x)['label'])\n",
    "\n",
    "irony_counts = transformed_tweets_irony['irony'].value_counts()\n",
    "number_irony_tweets = irony_counts.loc['irony'] if 'irony' in irony_counts else 0\n",
    "\n",
    "print(f'Number of ironic tweets: {number_irony_tweets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text     author_id  \\\n",
      "0   @TLRailUK You opened the doors 20 seconds afte...  2.008622e+07   \n",
      "23  @TLRailUK 0930 at ECR (on late 0807 BTN to LBG...  4.686315e+08   \n",
      "34  @TLRailUK it seems remarkable that the train i...  5.324844e+08   \n",
      "46  Thanks... for nothing! @TLRailUK No paper in t...  1.101208e+18   \n",
      "53  Delightful @TLRailUK train this morning - fill...  2.503814e+09   \n",
      "54  Oh great, looks like @TLRailUK on-train WiFi d...  7.696183e+07   \n",
      "68  Govia Thameslink fined Â£1m over Gatwick Expres...  1.089150e+18   \n",
      "80  The seats on @TLRailUK are made to give you ba...  7.695022e+08   \n",
      "83  Commuting public: \"hurrah, the school holidays...  1.155034e+08   \n",
      "88  Taking the Biscuit?! Sweet treat apology from ...  5.351682e+08   \n",
      "\n",
      "          date      time  irony  \n",
      "0   2019-01-16  18:45:31  irony  \n",
      "23  2019-08-14  08:33:01  irony  \n",
      "34  2019-01-22  07:58:09  irony  \n",
      "46  2019-05-29  18:30:26  irony  \n",
      "53  2020-01-23  07:00:43  irony  \n",
      "54  2019-10-09  15:40:29  irony  \n",
      "68  2019-07-17  10:35:00  irony  \n",
      "80  2019-11-05  23:48:30  irony  \n",
      "83  2019-07-22  07:22:07  irony  \n",
      "88  2019-05-29  16:41:52  irony  \n"
     ]
    }
   ],
   "source": [
    "# Printing rows if irony column is equals to irony\n",
    "ironic_tweets = transformed_tweets_irony[transformed_tweets_irony['irony'] == 'irony']\n",
    "print(ironic_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets to be fed to ChatGPT: 33\n"
     ]
    }
   ],
   "source": [
    "# Adding a column with the sentiment of the tweet and filter out the tweets that are not negative.\n",
    "model = tweetnlp.load_model('sentiment')\n",
    "transformed_tweets_sentiment = transformed_tweets_irony.copy()\n",
    "\n",
    "transformed_tweets_sentiment['sentiment'] = transformed_tweets_sentiment['text'].apply(lambda x: model.predict(x)['label'])\n",
    "\n",
    "# Filtering out the tweets that are not negative and not ironic\n",
    "transformed_tweets_sentiment = transformed_tweets_sentiment[(transformed_tweets_sentiment['irony'] == 'irony') | (transformed_tweets_sentiment['sentiment'] == 'negative')]\n",
    "\n",
    "number_complaints = transformed_tweets_sentiment.shape[0]\n",
    "print(f'Number of tweets to be fed to ChatGPT: {number_complaints}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            PLEASE EVALUATE UNTIL HERE. DO NOT CONTINUE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare Data for LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_tweets = df_filter_sentiment[['text', 'date', 'irony']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LLM Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import OPENAI_API_KEY\n",
    "\n",
    "OPENAI_API_KEY = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Date Created: 2019-09-29\n",
      "- Topic: Irony\n",
      "- Count of complaints for this topic: 4\n",
      "- Summary: Passengers are expressing complaints sarcastically or ironically.\n",
      "- Suggestion: It is important to acknowledge the sarcasm or irony in these complaints and reply with a light-hearted tone to show understanding and good humor.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Train Conditions\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are experiencing uncomfortable train conditions, such as low temperature and lack of toilet facilities.\n",
      "- Suggestion: Ensure that trains are maintained at appropriate temperatures and that all facilities, including toilets, are in working order. Promptly address any malfunctions and provide alternate options if necessary.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Staff Conduct and Service\n",
      "- Count of complaints for this topic: 3\n",
      "- Summary: Passengers are dissatisfied with the lack of information and announcements from staff during disruptions or incidents.\n",
      "- Suggestion: Improve communication with passengers by providing regular updates during incidents and disruptions. Train staff should be trained to effectively communicate with passengers and provide accurate information promptly.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Onboard Amenities\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are frustrated when train doors are not opened at their designated stops.\n",
      "- Suggestion: Ensure that train doors are consistently opened at all designated stops. Drivers should be trained to be attentive to passengers' needs and maintain proper functionality of doors.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Communication and Information\n",
      "- Count of complaints for this topic: 4\n",
      "- Summary: Passengers are expressing frustration with the lack of communication and information provided during disruptions or incidents.\n",
      "- Suggestion: Improve communication channels by ensuring that accurate and timely information is shared with passengers. Develop a robust system for providing announcements and updates during incidents to keep passengers informed.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Other\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are frustrated with the lack of coordination between Eurostar and Thameslink, resulting in delays.\n",
      "- Suggestion: Strengthen coordination between Eurostar and Thameslink to minimize delays and improve the overall travel experience for passengers. Foster better communication and collaboration between the two entities to address potential issues and find solutions.\n"
     ]
    }
   ],
   "source": [
    "# Constructing the prompt for OpenAI\n",
    "prompt = \"\"\"\n",
    "As a senior train maintenance official, I am consolidating passenger complaints for efficient resolution. \n",
    "Below are various tweets from train passengers. \n",
    "As our customer's opinion is very important to us, analyze each message. \n",
    "Categorize each message as a complaint or not a complaint.\n",
    "Complaints should be further categorized by one of these topics: Train Conditions, Staff Conduct and Service, Station Facilities, Safety and Security, Onboard Amenities, Communication and Information, Accessibility, Other.\n",
    "When the category is 'Other', please write what the complaint is about.\n",
    "If there is no complaint for a certain category, ignore that category.\n",
    "Please note that some tweets are marked with 'irony'. Pay special attention to these and interpret them carefully.\n",
    "Ignore the tweets that are not complaints.\n",
    "\n",
    "Complaints:\n",
    "\"\"\"\n",
    "\n",
    "complaint_summary = day_tweets.groupby(['text', 'date', 'irony']).size().reset_index(name='count')\n",
    "\n",
    "for index, row in complaint_summary.iterrows():\n",
    "    irony_tag = \"Irony\" if row['irony'] == 'irony' else \"Non-Irony\"\n",
    "    prompt += f\"- Date Created: {row['date']} - Complaint: {row['text']} - {irony_tag} (Count: {row['count']})\\n\"\n",
    "\n",
    "prompt += \"\"\"\n",
    "For each complaint, provide:\n",
    "1. Summary of the complaint in a very concise manner\n",
    "2. Topic (1 or 2 words)\n",
    "3. Suggestion for resolution with actionable steps starting from the next day\n",
    "\n",
    "Please structure your response as follows:\n",
    "- Date Created:\n",
    "- Topic:\n",
    "- Count of complaints for this topic:\n",
    "- Summary:\n",
    "- Suggestion:\n",
    "\"\"\"\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Generate response from OpenAI\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # Replace with the appropriate chat model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior train maintenance official.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message[\"content\"])\n",
    "data = response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Complaint</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Irony</td>\n",
       "      <td>4</td>\n",
       "      <td>Passengers are expressing complaints sarcastic...</td>\n",
       "      <td>It is important to acknowledge the sarcasm or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Train Conditions</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are experiencing uncomfortable trai...</td>\n",
       "      <td>Ensure that trains are maintained at appropria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Staff Conduct and Service</td>\n",
       "      <td>3</td>\n",
       "      <td>Passengers are dissatisfied with the lack of i...</td>\n",
       "      <td>Improve communication with passengers by provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Onboard Amenities</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are frustrated when train doors are...</td>\n",
       "      <td>Ensure that train doors are consistently opene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Communication and Information</td>\n",
       "      <td>4</td>\n",
       "      <td>Passengers are expressing frustration with the...</td>\n",
       "      <td>Improve communication channels by ensuring tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are frustrated with the lack of coo...</td>\n",
       "      <td>Strengthen coordination between Eurostar and T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date of Complaint                          Topic  Count  \\\n",
       "0        2019-09-29                          Irony      4   \n",
       "1        2019-09-29               Train Conditions      1   \n",
       "2        2019-09-29      Staff Conduct and Service      3   \n",
       "3        2019-09-29              Onboard Amenities      1   \n",
       "4        2019-09-29  Communication and Information      4   \n",
       "5        2019-09-29                          Other      1   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Passengers are expressing complaints sarcastic...   \n",
       "1  Passengers are experiencing uncomfortable trai...   \n",
       "2  Passengers are dissatisfied with the lack of i...   \n",
       "3  Passengers are frustrated when train doors are...   \n",
       "4  Passengers are expressing frustration with the...   \n",
       "5  Passengers are frustrated with the lack of coo...   \n",
       "\n",
       "                                          Suggestion  \n",
       "0  It is important to acknowledge the sarcasm or ...  \n",
       "1  Ensure that trains are maintained at appropria...  \n",
       "2  Improve communication with passengers by provi...  \n",
       "3  Ensure that train doors are consistently opene...  \n",
       "4  Improve communication channels by ensuring tha...  \n",
       "5  Strengthen coordination between Eurostar and T...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into separate entries\n",
    "entries = data.strip().split(\"- Date Created:\")\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "dates = []\n",
    "topics = []\n",
    "counts = []\n",
    "summaries = []\n",
    "suggestions = []\n",
    "\n",
    "# Process each entry\n",
    "for entry in entries:\n",
    "    if entry:  # skip empty strings\n",
    "        lines = entry.strip().split(\"\\n- \")\n",
    "        date, topic, count, summary, suggestion = lines\n",
    "        dates.append(date.replace(\"Date Created: \", \"\").strip())\n",
    "        topics.append(topic.replace(\"Topic: \", \"\").strip())\n",
    "        counts.append(int(count.split(\": \")[1]))\n",
    "        summaries.append(summary.replace(\"Summary: \", \"\").strip())\n",
    "        suggestions.append(suggestion.replace(\"Suggestion: \", \"\").strip())\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Date of Complaint': dates,\n",
    "    'Topic': topics,\n",
    "    'Count': counts,\n",
    "    'Summary': summaries,\n",
    "    'Suggestion': suggestions\n",
    "})\n",
    "\n",
    "df  # To display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total number</th>\n",
       "      <th>\"delay\" tweets</th>\n",
       "      <th>Ironic tweets</th>\n",
       "      <th>Tweets to be fed to ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total number  \"delay\" tweets  Ironic tweets  Tweets to be fed to ChatGPT\n",
       "0            74              50              5                           15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a summary dataframe with number_selected, number_delay_tweets, number_irony_tweets, number_complaints\n",
    "\n",
    "summary_df = pd.DataFrame({'Total number': number_selected, '\"delay\" tweets': number_delay_tweets, 'Ironic tweets': number_irony_tweets, 'Tweets to be fed to ChatGPT': number_complaints}, index=[0])\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
