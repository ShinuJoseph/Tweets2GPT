{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Erjon\\Documents\\1. GERMANY\\1. HTW Berlin\\3. Courses\\3.1 - Project Management and Data Analytics Lab\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-24 10:19:16,928\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-11-24 10:19:17,103\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import tweetnlp\n",
    "import openai\n",
    "\n",
    "# import functions\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Functions/')  # Adjust the relative path as needed\n",
    "\n",
    "from json_transform import get_all_keys, flatten_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Transform the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "The JSON data is nested, so we need to flatten it to be able to convert it to a DataFrame.\n",
    "We will use the get_all_keys() and flatten_json() functions from the json_transform.py file.\n",
    "After getting all the keys, we will convert them to a list and then flatten the JSON data.\n",
    "Convert the flattened data to a DataFrame and filter out the rows that contain \"update\" in the text column.\n",
    "'''\n",
    "\n",
    "with open(\"../../Data/Raw/tweets_ws23_v1.json\", \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "all_keys = get_all_keys(json_data)\n",
    "all_keys_list = list(all_keys)\n",
    "flattened_data = [flatten_json(entry) for entry in json_data]\n",
    "all_tweets = pd.DataFrame(flattened_data)\n",
    "\n",
    "# filter out the rows that contain \"update\" in the text column\n",
    "\n",
    "all_tweets = all_tweets[~all_tweets['text'].str.contains(\"update\")]\n",
    "number_total_tweets = all_tweets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 15824\n",
      "Total number of tweets after dropping duplicates: 14683\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will now drop the columns that we don't need and rename the columns that we will use.\n",
    "Then split the source_created_at column into date and time for easier analysis.\n",
    "Finally, we will drop the duplicated tweets.\n",
    "'''\n",
    "\n",
    "transformed_tweets = all_tweets[['text', 'author_id', 'source_created_at']].copy()\n",
    "print(f'Total number of tweets: {transformed_tweets.shape[0]}')\n",
    "\n",
    "transformed_tweets['date'] = transformed_tweets['source_created_at'].apply(lambda x: x.split(' ')[0])\n",
    "transformed_tweets['time'] = transformed_tweets['source_created_at'].apply(lambda x: x.split(' ')[1].split('.')[0])\n",
    "transformed_tweets.drop(['source_created_at'], axis=1, inplace=True)\n",
    "\n",
    "transformed_tweets = transformed_tweets.drop_duplicates(subset=['text'])\n",
    "\n",
    "print(f'Total number of tweets after dropping duplicates: {transformed_tweets.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Group the tweets by date and create a dictionary with the date as the key and the dataframe as the value.\n",
    "To access the dataframe for a specific date, use the date_dfs dictionary and the date as the key.\n",
    "Example: date_dfs['2021-05-01']'''\n",
    "\n",
    "grouped_tweets = transformed_tweets.groupby('date')\n",
    "date_dfs = {date: group for date, group in grouped_tweets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filter the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date 2019-09-29 is valid and has 74 tweets.\n"
     ]
    }
   ],
   "source": [
    "selected_date = '2019-09-29'\n",
    "\n",
    "number_selected = date_dfs[selected_date].shape[0]\n",
    "\n",
    "# Check if the selected date is in the date_dfs dictionary\n",
    "if selected_date in date_dfs:\n",
    "    # You can now work with selected_df, which is the DataFrame for the selected date\n",
    "    print(f\"Date {selected_date} is valid and has {date_dfs[selected_date].shape[0]} tweets.\")\n",
    "else:\n",
    "    print(f\"Date {selected_date} is not available in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets after filtering out the word \"delay\": 24\n"
     ]
    }
   ],
   "source": [
    "# filter out the tweets that contain the word \"delay\"\n",
    "df_filter_delay = date_dfs[selected_date][~date_dfs[selected_date]['text'].str.contains('delay', case=False, na=False)]\n",
    "number_delay_tweets = number_selected - df_filter_delay.shape[0]\n",
    "\n",
    "print(f'Number of tweets after filtering out the word \"delay\": {df_filter_delay.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ironic tweets: 5\n"
     ]
    }
   ],
   "source": [
    "# Check for irony in the tweets using the tweetnlp library and save the results in a new column\n",
    "\n",
    "model_irony = tweetnlp.load_model('irony')\n",
    "df_filter_irony = df_filter_delay.copy()\n",
    "df_filter_irony['irony'] = df_filter_irony['text'].apply(lambda x: model_irony.predict(x)['label'])\n",
    "\n",
    "irony_counts = df_filter_irony['irony'].value_counts()\n",
    "number_irony_tweets = irony_counts.loc['irony'] if 'irony' in irony_counts else 0\n",
    "\n",
    "print(f'Number of ironic tweets: {number_irony_tweets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets to be fed to ChatGPT: 15\n"
     ]
    }
   ],
   "source": [
    "# Add a column with the sentiment of the tweet and filter out the tweets that are not negative.\n",
    "\n",
    "model = tweetnlp.load_model('sentiment')\n",
    "df_filter_sentiment = df_filter_irony.copy()\n",
    "\n",
    "df_filter_sentiment['sentiment'] = df_filter_sentiment['text'].apply(lambda x: model.predict(x)['label'])\n",
    "\n",
    "# filter out the tweets that are not negative and not ironic\n",
    "\n",
    "df_filter_sentiment = df_filter_sentiment[(df_filter_sentiment['irony'] == 'irony') | (df_filter_sentiment['sentiment'] == 'negative')]\n",
    "\n",
    "number_complaints = df_filter_sentiment.shape[0]\n",
    "print(f'Number of tweets to be fed to ChatGPT: {number_complaints}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare Data for LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_tweets = df_filter_sentiment[['text', 'date', 'irony']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LLM Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import OPENAI_API_KEY\n",
    "\n",
    "OPENAI_API_KEY = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Date Created: 2019-09-29\n",
      "- Topic: Irony\n",
      "- Count of complaints for this topic: 4\n",
      "- Summary: Passengers are expressing complaints sarcastically or ironically.\n",
      "- Suggestion: It is important to acknowledge the sarcasm or irony in these complaints and reply with a light-hearted tone to show understanding and good humor.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Train Conditions\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are experiencing uncomfortable train conditions, such as low temperature and lack of toilet facilities.\n",
      "- Suggestion: Ensure that trains are maintained at appropriate temperatures and that all facilities, including toilets, are in working order. Promptly address any malfunctions and provide alternate options if necessary.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Staff Conduct and Service\n",
      "- Count of complaints for this topic: 3\n",
      "- Summary: Passengers are dissatisfied with the lack of information and announcements from staff during disruptions or incidents.\n",
      "- Suggestion: Improve communication with passengers by providing regular updates during incidents and disruptions. Train staff should be trained to effectively communicate with passengers and provide accurate information promptly.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Onboard Amenities\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are frustrated when train doors are not opened at their designated stops.\n",
      "- Suggestion: Ensure that train doors are consistently opened at all designated stops. Drivers should be trained to be attentive to passengers' needs and maintain proper functionality of doors.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Communication and Information\n",
      "- Count of complaints for this topic: 4\n",
      "- Summary: Passengers are expressing frustration with the lack of communication and information provided during disruptions or incidents.\n",
      "- Suggestion: Improve communication channels by ensuring that accurate and timely information is shared with passengers. Develop a robust system for providing announcements and updates during incidents to keep passengers informed.\n",
      "\n",
      "- Date Created: 2019-09-29\n",
      "- Topic: Other\n",
      "- Count of complaints for this topic: 1\n",
      "- Summary: Passengers are frustrated with the lack of coordination between Eurostar and Thameslink, resulting in delays.\n",
      "- Suggestion: Strengthen coordination between Eurostar and Thameslink to minimize delays and improve the overall travel experience for passengers. Foster better communication and collaboration between the two entities to address potential issues and find solutions.\n"
     ]
    }
   ],
   "source": [
    "# Constructing the prompt for OpenAI\n",
    "prompt = \"\"\"\n",
    "As a senior train maintenance official, I am consolidating passenger complaints for efficient resolution. \n",
    "Below are various tweets from train passengers. \n",
    "As our customer's opinion is very important to us, analyze each message. \n",
    "Categorize each message as a complaint or not a complaint.\n",
    "Complaints should be further categorized by one of these topics: Train Conditions, Staff Conduct and Service, Station Facilities, Safety and Security, Onboard Amenities, Communication and Information, Accessibility, Other.\n",
    "When the category is 'Other', please write what the complaint is about.\n",
    "If there is no complaint for a certain category, ignore that category.\n",
    "Please note that some tweets are marked with 'irony'. Pay special attention to these and interpret them carefully.\n",
    "Ignore the tweets that are not complaints.\n",
    "\n",
    "Complaints:\n",
    "\"\"\"\n",
    "\n",
    "complaint_summary = day_tweets.groupby(['text', 'date', 'irony']).size().reset_index(name='count')\n",
    "\n",
    "for index, row in complaint_summary.iterrows():\n",
    "    irony_tag = \"Irony\" if row['irony'] == 'irony' else \"Non-Irony\"\n",
    "    prompt += f\"- Date Created: {row['date']} - Complaint: {row['text']} - {irony_tag} (Count: {row['count']})\\n\"\n",
    "\n",
    "prompt += \"\"\"\n",
    "For each complaint, provide:\n",
    "1. Summary of the complaint in a very concise manner\n",
    "2. Topic (1 or 2 words)\n",
    "3. Suggestion for resolution with actionable steps starting from the next day\n",
    "\n",
    "Please structure your response as follows:\n",
    "- Date Created:\n",
    "- Topic:\n",
    "- Count of complaints for this topic:\n",
    "- Summary:\n",
    "- Suggestion:\n",
    "\"\"\"\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Generate response from OpenAI\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # Replace with the appropriate chat model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior train maintenance official.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message[\"content\"])\n",
    "data = response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Complaint</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Irony</td>\n",
       "      <td>4</td>\n",
       "      <td>Passengers are expressing complaints sarcastic...</td>\n",
       "      <td>It is important to acknowledge the sarcasm or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Train Conditions</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are experiencing uncomfortable trai...</td>\n",
       "      <td>Ensure that trains are maintained at appropria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Staff Conduct and Service</td>\n",
       "      <td>3</td>\n",
       "      <td>Passengers are dissatisfied with the lack of i...</td>\n",
       "      <td>Improve communication with passengers by provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Onboard Amenities</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are frustrated when train doors are...</td>\n",
       "      <td>Ensure that train doors are consistently opene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Communication and Information</td>\n",
       "      <td>4</td>\n",
       "      <td>Passengers are expressing frustration with the...</td>\n",
       "      <td>Improve communication channels by ensuring tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Passengers are frustrated with the lack of coo...</td>\n",
       "      <td>Strengthen coordination between Eurostar and T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date of Complaint                          Topic  Count  \\\n",
       "0        2019-09-29                          Irony      4   \n",
       "1        2019-09-29               Train Conditions      1   \n",
       "2        2019-09-29      Staff Conduct and Service      3   \n",
       "3        2019-09-29              Onboard Amenities      1   \n",
       "4        2019-09-29  Communication and Information      4   \n",
       "5        2019-09-29                          Other      1   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Passengers are expressing complaints sarcastic...   \n",
       "1  Passengers are experiencing uncomfortable trai...   \n",
       "2  Passengers are dissatisfied with the lack of i...   \n",
       "3  Passengers are frustrated when train doors are...   \n",
       "4  Passengers are expressing frustration with the...   \n",
       "5  Passengers are frustrated with the lack of coo...   \n",
       "\n",
       "                                          Suggestion  \n",
       "0  It is important to acknowledge the sarcasm or ...  \n",
       "1  Ensure that trains are maintained at appropria...  \n",
       "2  Improve communication with passengers by provi...  \n",
       "3  Ensure that train doors are consistently opene...  \n",
       "4  Improve communication channels by ensuring tha...  \n",
       "5  Strengthen coordination between Eurostar and T...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into separate entries\n",
    "entries = data.strip().split(\"- Date Created:\")\n",
    "\n",
    "# Initialize lists to hold the data\n",
    "dates = []\n",
    "topics = []\n",
    "counts = []\n",
    "summaries = []\n",
    "suggestions = []\n",
    "\n",
    "# Process each entry\n",
    "for entry in entries:\n",
    "    if entry:  # skip empty strings\n",
    "        lines = entry.strip().split(\"\\n- \")\n",
    "        date, topic, count, summary, suggestion = lines\n",
    "        dates.append(date.replace(\"Date Created: \", \"\").strip())\n",
    "        topics.append(topic.replace(\"Topic: \", \"\").strip())\n",
    "        counts.append(int(count.split(\": \")[1]))\n",
    "        summaries.append(summary.replace(\"Summary: \", \"\").strip())\n",
    "        suggestions.append(suggestion.replace(\"Suggestion: \", \"\").strip())\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Date of Complaint': dates,\n",
    "    'Topic': topics,\n",
    "    'Count': counts,\n",
    "    'Summary': summaries,\n",
    "    'Suggestion': suggestions\n",
    "})\n",
    "\n",
    "df  # To display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total number</th>\n",
       "      <th>\"delay\" tweets</th>\n",
       "      <th>Ironic tweets</th>\n",
       "      <th>Tweets to be fed to ChatGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total number  \"delay\" tweets  Ironic tweets  Tweets to be fed to ChatGPT\n",
       "0            74              50              5                           15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a summary dataframe with number_selected, number_delay_tweets, number_irony_tweets, number_complaints\n",
    "\n",
    "summary_df = pd.DataFrame({'Total number': number_selected, '\"delay\" tweets': number_delay_tweets, 'Ironic tweets': number_irony_tweets, 'Tweets to be fed to ChatGPT': number_complaints}, index=[0])\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
